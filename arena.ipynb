{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML_bot training\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./models\")\n",
    "\n",
    "from ML_bot import train_model\n",
    "\n",
    "train_model(\"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roti/workspace/uni_projects/cardbot/models/Deepbot.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current progress: game 0\n",
      "DLBot: 373\n",
      "Randy: 518\n",
      "Rdeep: 609\n"
     ]
    }
   ],
   "source": [
    "# Round robin tournament, 3 bots\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./models\")\n",
    "from ML_bot import MLPlayingBot\n",
    "from schnapsen.bots import RdeepBot\n",
    "from schnapsen.bots import RandBot\n",
    "from Deepbot import DeepLearningBot\n",
    "from schnapsen.game import SchnapsenGamePlayEngine\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "\n",
    "engine = SchnapsenGamePlayEngine()\n",
    "model_dir = \"ML_models\"\n",
    "model_name = \"simple_model\"\n",
    "model_location = pathlib.Path(model_dir) / model_name\n",
    "\n",
    "model_path = \"./models/model_20250112_044306_epochs25_batch128_lr0.004.pt\"\n",
    "\n",
    "rng = random.Random(42)\n",
    "\n",
    "bot1 = MLPlayingBot(model_location, name=\"MLBot\")\n",
    "bot2 = RandBot(rng, \"RandBot\")\n",
    "bot3 = RdeepBot(num_samples=5, depth=2, rand=rng, name=\"RdeepBot\")\n",
    "bot4 = DeepLearningBot(model_path=model_path, input_size=173, hidden_size=64, name=\"DLbot\")\n",
    "\n",
    "def round_robin_tournament():\n",
    "    wins_MLBot = 0\n",
    "    wins_RDeep = 0\n",
    "    wins_Randy = 0\n",
    "    for i in range (500):\n",
    "\n",
    "        if i + 1 % 500 == 0:\n",
    "            print(f\"Current progress: game {i}\")\n",
    "\n",
    "        winner_id, game_points, score = engine.play_game(bot1, bot4, random.Random(i))\n",
    "\n",
    "        if winner_id._Bot__name == \"DLbot\":\n",
    "            wins_MLBot +=1\n",
    "        elif winner_id._Bot__name == \"RdeepBot\":\n",
    "            wins_RDeep +=1\n",
    "        else:\n",
    "            wins_Randy +=1\n",
    "\n",
    "        winner_id2, game_points2, score2 = engine.play_game(bot1, bot3, random.Random(i))\n",
    "\n",
    "        if winner_id2._Bot__name == \"DLbot\":\n",
    "            wins_MLBot +=1\n",
    "        elif winner_id2._Bot__name == \"RdeepBot\":\n",
    "            wins_RDeep +=1\n",
    "        else:\n",
    "            wins_Randy +=1\n",
    "\n",
    "        winner_id3, game_points3, score3 = engine.play_game(bot4, bot3, random.Random(i))\n",
    "\n",
    "        if winner_id3._Bot__name == \"DLbot\":\n",
    "            wins_MLBot +=1\n",
    "        elif winner_id3._Bot__name == \"RdeepBot\":\n",
    "            wins_RDeep +=1\n",
    "        else:\n",
    "            wins_Randy +=1\n",
    "\n",
    "\n",
    "\n",
    "    print (f\"DLBot: {wins_MLBot}\")\n",
    "    print (f\"Randy: {wins_Randy}\")\n",
    "    print (f\"Rdeep: {wins_RDeep}\")\n",
    "\n",
    "round_robin_tournament()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RdeepBot wins: 41\n",
      "RdeepBot2 wins: 59\n"
     ]
    }
   ],
   "source": [
    "# 1v1 arena\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./models\")\n",
    "from ML_bot import MLPlayingBot\n",
    "from schnapsen.bots import RdeepBot\n",
    "from schnapsen.bots import RandBot\n",
    "from Deepbot import DeepLearningBot\n",
    "from schnapsen.game import SchnapsenGamePlayEngine\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "\n",
    "engine = SchnapsenGamePlayEngine()\n",
    "model_dir = \"ML_models\"\n",
    "model_name = \"simple_model\"\n",
    "model_location = pathlib.Path(model_dir) / model_name\n",
    "\n",
    "model_path = \"./models/model_20250112_044306_epochs25_batch128_lr0.004.pt\"\n",
    "\n",
    "rng = random.Random(42)\n",
    "\n",
    "bot1 = MLPlayingBot(model_location, name=\"MLBot\")\n",
    "bot2 = RandBot(rng, \"RandBot\")\n",
    "bot3 = RdeepBot(num_samples=10, depth=3, rand=rng, name=\"RdeepBot\")\n",
    "bot4 = DeepLearningBot(model_path=model_path, input_size=173, hidden_size=64, name=\"DLbot\")\n",
    "bot5 = RdeepBot(num_samples=20, depth=5, rand=rng, name=\"RdeepBot2\")\n",
    "\n",
    "def matches_1v1(bot1, bot2):\n",
    "    wins_bot1 = 0\n",
    "    wins_bot2 = 0\n",
    "    \n",
    "    for i in range (100):\n",
    "\n",
    "        if i + 1 % 500 == 0:\n",
    "            print(f\"Current progress: game {i}\")\n",
    "\n",
    "        winner_id, game_points, score = engine.play_game(bot1, bot2, random.Random(i))\n",
    "\n",
    "        if winner_id._Bot__name == str(bot1):\n",
    "            wins_bot1 +=1\n",
    "        elif winner_id._Bot__name == str(bot2):\n",
    "            wins_bot2 +=1\n",
    "\n",
    "\n",
    "    print (f\"{str(bot1)} wins: {wins_bot1}\")\n",
    "    print (f\"{str(bot2)} wins: {wins_bot2}\")\n",
    "\n",
    "matches_1v1(bot3, bot5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning training\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./models\")\n",
    "from Deepbot import train_DL_model, gpu_check\n",
    "\n",
    "# gpu_check()\n",
    "\n",
    "data_file = \"./ML_replay_memories/replay_memory.txt\"  # Replace with your data file path\n",
    "output_model_path = \"./models\"\n",
    "input_dim = 173\n",
    "hidden_dim = 64\n",
    "train_DL_model(data_file, output_model_path, input_dim, hidden_dim, batch_size = 128, epochs = 25, lr = 0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing dataset found at ML_replay_memories/replay_memory.txt. Overwriting...\n",
      "Game 500 completed.\n",
      "Game 1000 completed.\n",
      "Game 1500 completed.\n",
      "Game 2000 completed.\n",
      "Game 2500 completed.\n",
      "Game 3000 completed.\n",
      "Game 3500 completed.\n",
      "Game 4000 completed.\n",
      "Game 4500 completed.\n",
      "Game 5000 completed.\n",
      "Game 5500 completed.\n",
      "Game 6000 completed.\n",
      "Game 6500 completed.\n",
      "Game 7000 completed.\n",
      "Game 7500 completed.\n",
      "Game 8500 completed.\n",
      "Game 9000 completed.\n",
      "Game 9500 completed.\n",
      "Game 8000 completed.\n",
      "Game 10000 completed.\n"
     ]
    }
   ],
   "source": [
    "#Data generation\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./data_gen\")\n",
    "\n",
    "from data_generation import create_replay_memory_dataset\n",
    "import random\n",
    "from schnapsen.bots import RandBot\n",
    "from schnapsen.bots import RdeepBot\n",
    "from schnapsen.bots import BullyBot\n",
    "\n",
    "rng = random.Random(42)\n",
    "\n",
    "bot1 = RandBot(rng)\n",
    "bot2 = RdeepBot(num_samples=5, depth=3, rand=rng)\n",
    "bot4 = BullyBot(rng)\n",
    "\n",
    "create_replay_memory_dataset(bot1=bot2, bot2=bot2, num_of_games = 10000, parallel = True, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepCFR training\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"./models\")\n",
    "sys.path.append(\"./CFRmodels\")\n",
    "\n",
    "\n",
    "from DeepCFR import load_txt_dataset, create_data_loader, DeepCFR\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset from text file\n",
    "file_path = \"./ML_replay_memories/replay_memory.txt\"  # Replace with your dataset file\n",
    "features, regrets = load_txt_dataset(file_path, label_type=\"regret\")  # Load regret data\n",
    "_, strategies = load_txt_dataset(file_path, label_type=\"strategy\")   # Load strategy data\n",
    "\n",
    "# Verify dataset dimensions\n",
    "print(\"Features shape:\", features.shape)  # Should match number of rows and feature length\n",
    "print(\"Regrets shape:\", np.array(regrets).shape)  # Should match rows and action size\n",
    "print(\"Strategies shape:\", np.array(strategies).shape)  # Should match rows and action size\n",
    "\n",
    "# Create DataLoaders for training\n",
    "regret_loader = create_data_loader(features, regrets, batch_size=64, shuffle=True)\n",
    "strategy_loader = create_data_loader(features, strategies, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize the DeepCFR model\n",
    "deep_cfr = DeepCFR(input_size=features.shape[1], action_size=len(regrets[0]))\n",
    "\n",
    "for batch_idx, (states, labels) in enumerate(regret_loader):\n",
    "    print(f\"Batch {batch_idx + 1}: States sample indices:\")\n",
    "    print(states[:5])  # Assuming states contain identifiable indices\n",
    "    if batch_idx == 2:  # Inspect only the first three batches\n",
    "        break\n",
    "\n",
    "# Train regret network\n",
    "print(\"Training regret network...\")\n",
    "deep_cfr.train_regret_network(regret_loader, epochs=10)\n",
    "\n",
    "# Train strategy network\n",
    "print(\"Training strategy network...\")\n",
    "deep_cfr.train_strategy_network(strategy_loader, epochs=10)\n",
    "\n",
    "torch.save(deep_cfr.regret_net.state_dict(), \"./CFRmodels/regret_net.pth\")\n",
    "torch.save(deep_cfr.strategy_net.state_dict(), \"./CFRmodels/strategy_net.pth\")\n",
    "\n",
    "print(\"Trained networks saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
